import { AIModel } from '../../types/ai';

export const AI_MODELS: AIModel[] = [
  // OpenAI GPT-4 Models
  {
    id: 'gpt-4',
    name: 'GPT-4',
    provider: 'openai',
    category: 'chat',
    description: 'Most capable base GPT-4 model',
    isConfigured: true,
    color: '#3B7443',
    endpoint: 'chat',
    rateLimits: {
      tpm: 10000,
      rpm: 500,
      rpd: 10000,
      tpd: 100000,
    },
  },
  {
    id: 'gpt-4-turbo',
    name: 'GPT-4 Turbo',
    provider: 'openai',
    category: 'chat',
    description: 'Enhanced GPT-4 with higher rate limits',
    isConfigured: true,
    color: '#3B7443',
    endpoint: 'chat',
    rateLimits: {
      tpm: 30000,
      rpm: 500,
      tpd: 90000,
    },
  },
  {
    id: 'gpt-4o',
    name: 'GPT-4 Optimized',
    provider: 'openai',
    category: 'chat',
    description: 'Optimized version of GPT-4',
    isConfigured: true,
    color: '#3B7443',
    endpoint: 'chat',
    rateLimits: {
      tpm: 30000,
      rpm: 500,
      tpd: 90000,
    },
  },
  {
    id: 'gpt-4o-mini',
    name: 'GPT-4 Optimized Mini',
    provider: 'openai',
    category: 'chat',
    description: 'Lightweight GPT-4 with higher token limits',
    isConfigured: true,
    color: '#3B7443',
    endpoint: 'chat',
    rateLimits: {
      tpm: 200000,
      rpm: 500,
      rpd: 10000,
      tpd: 2000000,
    },
  },
  {
    id: 'gpt-3.5-turbo',
    name: 'GPT-3.5 Turbo',
    provider: 'openai',
    category: 'chat',
    description: 'Fast and cost-effective chat model',
    isConfigured: true,
    color: '#3B7443',
    endpoint: 'chat',
    rateLimits: {
      tpm: 200000,
      rpm: 500,
      rpd: 10000,
      tpd: 2000000,
    },
  },
  // OpenAI Embedding Models
  {
    id: 'text-embedding-3-small',
    name: 'Text Embedding 3 Small',
    provider: 'openai',
    category: 'embedding',
    description: 'Efficient text embedding generation',
    isConfigured: true,
    color: '#3B7443',
    endpoint: 'embeddings',
    rateLimits: {
      tpm: 1000000,
      rpm: 3000,
      tpd: 3000000,
    },
  },
  // OpenAI Image Models
  {
    id: 'dall-e-3',
    name: 'DALLÂ·E 3',
    provider: 'openai',
    category: 'image',
    description: 'Advanced image generation',
    isConfigured: true,
    color: '#3B7443',
    endpoint: 'images',
    rateLimits: {
      rpm: 500,
      imagesPerMinute: 5,
    },
  },
  // OpenAI Audio Models
  {
    id: 'whisper-1',
    name: 'Whisper v1',
    provider: 'openai',
    category: 'audio',
    description: 'Speech to text transcription',
    isConfigured: true,
    color: '#3B7443',
    endpoint: 'audio',
    rateLimits: {
      rpm: 500,
    },
  },
  {
    id: 'tts-1',
    name: 'TTS-1',
    provider: 'openai',
    category: 'audio',
    description: 'Text to speech conversion',
    isConfigured: true,
    color: '#3B7443',
    endpoint: 'audio',
    rateLimits: {
      rpm: 500,
    },
  },
  // Anthropic Models (Colored Orange)
  {
    id: 'claude-3-5-sonnet-20241022',
    name: 'Claude 3.5 Sonnet (latest)',
    provider: 'anthropic',
    category: 'chat',
    description: 'Most intelligent model with high capability and fast response times',
    isConfigured: true,
    color: '#F97316',
    endpoint: 'chat',
    rateLimits: {
      maxInputTokens: 200000,
      maxOutputTokens: 8192,
      tpm: 100000,
      rpm: 50,
    }
  },
  {
    id: 'claude-3-5-haiku-20241022',
    name: 'Claude 3.5 Haiku (latest)',
    provider: 'anthropic',
    category: 'chat',
    description: 'Fastest model with high intelligence and quick response times',
    isConfigured: true,
    color: '#F97316',
    endpoint: 'chat',
    rateLimits: {
      maxInputTokens: 200000,
      maxOutputTokens: 8192,
      tpm: 100000,
      rpm: 50,
    }
  },
  {
    id: 'claude-3-opus-20240229',
    name: 'Claude 3 Opus (latest)',
    provider: 'anthropic',
    category: 'chat',
    description: 'Most powerful model for highly complex tasks with top-level intelligence and understanding',
    isConfigured: true,
    color: '#F97316',
    endpoint: 'chat',
    rateLimits: {
      maxInputTokens: 200000,
      maxOutputTokens: 4096,
      tpm: 100000,
      rpm: 50,
    }
  },
  {
    id: 'claude-3-sonnet-20240229',
    name: 'Claude 3 Sonnet',
    provider: 'anthropic',
    category: 'chat',
    description: 'Balanced model optimized for production deployments with strong utility',
    isConfigured: true,
    color: '#F97316',
    endpoint: 'chat',
    rateLimits: {
      maxInputTokens: 200000,
      maxOutputTokens: 4096,
      tpm: 100000,
      rpm: 50,
    }
  },
  {
    id: 'claude-3-haiku-20240307',
    name: 'Claude 3 Haiku',
    provider: 'anthropic',
    category: 'chat',
    description: 'Fastest and most compact model for near-instant responsiveness',
    isConfigured: true,
    color: '#F97316',
    endpoint: 'chat',
    rateLimits: {
      maxInputTokens: 200000,
      maxOutputTokens: 4096,
      tpm: 100000,
      rpm: 50,
    }
  },
  // Llama Models (Colored Blue)
  {
    id: 'llama3.1:8b',
    name: 'Llama 3.1',
    provider: 'llama',
    category: 'chat',
    description: "Llama 3.1 - Meta's latest 8b parameter model",
    isConfigured: true,
    color: '#8B5CF6',
    endpoint: 'chat',
  },
  {
    id: 'llama3.2',
    name: 'Llama 3.2',
    provider: 'llama',
    category: 'chat',
    description: "Llama 3.2 - Meta's latest 3b parameter model",
    isConfigured: true,
    color: '#8B5CF6',
    endpoint: 'chat',
  },
  {
    id: 'deepseek-coder-v2',
    name: 'DeepSeek Coder V2',
    provider: 'llama',
    category: 'chat',
    description: 'An open-source Mixture-of-Experts code language model that achieves performance comparable to GPT4-Turbo in code-specific tasks.',
    isConfigured: true,
    color: '#8B5CF6',
    endpoint: 'chat',
  },
  {
    id: 'nemotron-mini',
    name: 'Nemotron Mini',
    provider: 'llama',
    category: 'chat',
    description: 'A commercial-friendly small language model by NVIDIA optimized for roleplay, RAG QA, and function calling.',
    isConfigured: true,
    color: '#8B5CF6',
    endpoint: 'chat',
  },
  {
    id: 'nemotron',
    name: 'Nemotron',
    provider: 'llama',
    category: 'chat',
    description: 'A commercial-friendly small language model by NVIDIA optimized for roleplay, RAG QA, and function calling.',
    isConfigured: true,
    color: '#8B5CF6',
    endpoint: 'chat',
  },
  {
    id: 'Mistral-nemo',
    name: 'Mistral Nemo',
    provider: 'llama',
    category: 'chat',
    description: 'A state-of-the-art 12B model with 128k context length, built by Mistral AI in collaboration with NVIDIA.',
    isConfigured: true,
    color: '#8B5CF6',
    endpoint: 'chat',
  },
  {
    id: 'orca2',
    name: 'Orca 2',
    provider: 'llama',
    category: 'chat',
    description: "Orca 2 is built by Microsoft research, and are a fine-tuned version of Meta's Llama 2 models. The model is designed to excel particularly in reasoning.",
    isConfigured: true,
    color: '#8B5CF6',
    endpoint: 'chat',
  },
  {
    id: 'samantha-mistral',
    name: 'Samantha Mistral',
    provider: 'llama',
    category: 'chat',
    description: 'A companion assistant trained in philosophy, psychology, and personal relationships. Based on Mistral.',
    isConfigured: true,
    color: '#8B5CF6',
    endpoint: 'chat',
  },
  {
    id: 'nexusraven',
    name: 'Nexus Raven (Tool Calling)',
    provider: 'llama',
    category: 'chat',
    description: 'Nexus Raven is a model designed to excel in function calling, and is optimized for tool calling.',
    isConfigured: true,
    color: '#8B5CF6',
    endpoint: 'chat',
  },
  {
    id: 'granite3-dense:8b',
    name: 'Granite 3 Dense',
    provider: 'llama',
    category: 'chat',
    description: 'The IBM Granite 2B and 8B models are designed to support tool-based use cases and support for retrieval augmented generation (RAG), streamlining code generation, translation and bug fixing.',
    isConfigured: true,
    color: '#8B5CF6',
    endpoint: 'chat',
  },
  {
    id: 'granite3-moe',
    name: 'Granite 3 MOE',
    provider: 'llama',
    category: 'chat',
    description: 'The IBM Granite 1B and 3B models are the first mixture of experts (MoE) Granite models from IBM designed for low latency usage.',
    isConfigured: true,
    color: '#8B5CF6',
    endpoint: 'chat',
  },
  {
    id: 'qwen2.5-coder:3b',
    name: 'Qwen 2.5 Coder 3b',
    provider: 'llama',
    category: 'chat',
    description: 'The latest series of Code-Specific Qwen models, with significant improvements in code generation, code reasoning, and code fixing.',
    isConfigured: true,
    color: '#8B5CF6',
    endpoint: 'chat',
  },
  {
    id: 'qwen2.5-coder:14b',
    name: 'Qwen 2.5 Coder 14b',
    provider: 'llama',
    category: 'chat',
    description: 'The latest series of Code-Specific Qwen models, with significant improvements in code generation, code reasoning, and code fixing.',
    isConfigured: true,
    color: '#8B5CF6',
    endpoint: 'chat',
  },
  {
    id: 'qwen2.5-coder:32b',
    name: 'Qwen 2.5 Coder 32b',
    provider: 'llama',
    category: 'chat',
    description: 'The latest series of Code-Specific Qwen models, with significant improvements in code generation, code reasoning, and code fixing.',
    isConfigured: true,
    color: '#8B5CF6',
    endpoint: 'chat',
  },
  {
    id: 'qwen2.5-coder:14b',
    name: 'Qwen 2.5 Coder 14b',
    provider: 'llama',
    category: 'function',
    description: 'The latest series of Code-Specific Qwen models, with significant improvements in code generation, code reasoning, and code fixing.',
    isConfigured: true,
    color: '#8B5CF6',
    endpoint: 'chat',
  },
  {
    id: 'qwen2.5-coder:32b',
    name: 'Qwen 2.5 Coder 32b',
    provider: 'llama',
    category: 'function',
    description: 'The latest series of Code-Specific Qwen models, with significant improvements in code generation, code reasoning, and code fixing.',
    isConfigured: true,
    color: '#8B5CF6',
    endpoint: 'chat',
  },
  {
    id: 'qwen2.5-coder:7b',
    name: 'Qwen 2.5 Coder 7b',
    provider: 'llama',
    category: 'function',
    description: 'The latest series of Code-Specific Qwen models, with significant improvements in code generation, code reasoning, and code fixing.',
    isConfigured: true,
    color: '#8B5CF6',
    endpoint: 'chat',
  },
  {
    id: 'phi3.5',
    name: 'Phi 3.5',
    provider: 'llama',
    category: 'chat',
    description: 'A lightweight AI model with 3.8 billion parameters with performance overtaking similarly and larger sized models.',
    isConfigured: true,
    color: '#8B5CF6',
    endpoint: 'chat',
  },
  {
    id: 'phi3:14b',
    name: 'Phi 3 14b',
    provider: 'llama',
    category: 'chat',
    description: 'Phi-3 is a family of lightweight 3B (Mini) and 14B (Medium) state-of-the-art open models by Microsoft.',
    isConfigured: true,
    color: '#8B5CF6',
    endpoint: 'chat',
  },
  // Gemini Models (Colored Purple)
  {
    id: 'codegemma',
    name: 'Code Gemma',
    provider: 'llama',
    category: 'chat',
    description: 'Local Code Gemma model (7b parameters) from Google via Ollama',
    isConfigured: true,
    color: '#8B5CF6',
    endpoint: 'chat',
  },
  {
    id: 'gemma2:9b',
    name: 'Gemma 2',
    provider: 'llama',
    category: 'chat',
    description: "Gemma 2 - Google's latest 9b parameter model",
    isConfigured: true,
    color: '#8B5CF6',
    endpoint: 'chat',
  },
  {
    id: 'gemma2:2b',
    name: 'Gemma 2 (2b)',
    provider: 'llama',
    category: 'chat',
    description: 'Local Gemma 2 model (2b parameters) from Google via Ollama',
    isConfigured: true,
    color: '#8B5CF6',
    endpoint: 'chat',
  },
  {
    id: 'opencoder:8b',
    name: 'OpenCoder 8b',
    provider: 'llama',
    category: 'chat',
    description: 'OpenCoder is an open and reproducible code LLM family which includes 1.5B and 8B models, supporting both chat and fill-in-the-middle for English and Chinese languages.',
    isConfigured: true,
    color: '#8B5CF6',
    endpoint: 'chat',
  },
  {
    id: 'opencoder:1.5b',
    name: 'OpenCoder 1.5b',
    provider: 'llama',
    category: 'chat',
    description: 'OpenCoder is an open and reproducible code LLM family which includes 1.5B and 8B models, supporting both chat and fill-in-the-middle for English and Chinese languages.',
    isConfigured: true,
    color: '#8B5CF6',
    endpoint: 'chat',
  },
  {
    id: 'solar-pro',
    name: 'Solar Pro',
    provider: 'llama',
    category: 'chat',
    description: 'Solar Pro Preview: an advanced language model (LLM) with 22 billion parameters designed to fit into a single GPU.',
    isConfigured: true,
    color: '#8B5CF6',
    endpoint: 'chat',
  },
  {
    id: 'athene-v2',
    name: 'Athene V2',
    provider: 'llama',
    category: 'chat',
    description: 'Athene-V2 is a 72B parameter model which excels at code completion, mathematics, and log extraction tasks.',
    isConfigured: true,
    color: '#8B5CF6',
    endpoint: 'chat',
  },
  {
    id: 'yi-coder',
    name: 'Yi Coder',
    provider: 'llama',
    category: 'chat',
    description: 'Yi-Coder is a series of open-source code language models that delivers state-of-the-art coding performance with fewer than 10 billion parameters.',
    isConfigured: true,
    color: '#8B5CF6',
    endpoint: 'chat',
  },
  {
    id: 'mxbai-embed-large',
    name: 'MXBai Embed Large',
    provider: 'llama',
    category: 'embedding',
    description: 'State-of-the-art large embedding model from mixedbread.ai',
    isConfigured: true,
    color: '#8B5CF6',
    endpoint: 'chat',
  },
  // Grok Models (Colored Blue)
  {
    id: 'grok-beta',
    name: 'Grok Beta',
    provider: 'grok',
    category: 'chat',
    description: 'Comparable performance to Grok 2 but with improved efficiency, speed and capabilities',
    isConfigured: true,
    color: '#1DA1F2', // X/Twitter blue color
    endpoint: 'chat',
    rateLimits: {
      tpm: 100000,
      rpm: 500,
      rpd: 10000,
      tpd: 1000000,
    },
  },
   // Grok Models (Colored Blue)
   {
    id: 'grok-beta',
    name: 'Grok Beta',
    provider: 'grok',
    category: 'function',
    description: 'Comparable performance to Grok 2 but with improved efficiency, speed and capabilities',
    isConfigured: true,
    color: '#1DA1F2', // X/Twitter blue color
    endpoint: 'chat',
    rateLimits: {
      tpm: 100000,
      rpm: 500,
      rpd: 10000,
      tpd: 1000000,
    },
  },
  {
    id: 'gemini-1.5-pro',
    name: 'Gemini 1.5 Pro',
    provider: 'gemini',
    category: 'chat',
    description: 'Google Gemini 1.5 Pro model for complex reasoning tasks.',
    isConfigured: true,
    color: '#4285F4',
    endpoint: 'chat',
    rateLimits: {
      tpm: 100000,
      rpm: 60,
    },
  },
  {
    id: 'gemini-1.5-flash',
    name: 'Gemini 1.5 Flash',
    provider: 'gemini',
    category: 'chat',
    description: 'Google Gemini 1.5 Flash model for chat and completion tasks.',
    isConfigured: true,
    color: '#4285F4',
    endpoint: 'chat',
    rateLimits: {
      tpm: 100000,
      rpm: 60,
    },
  },
  {
    id: 'gemini-1.5-flash-8b',
    name: 'Gemini 1.5 Flash-8B',
    provider: 'gemini',
    category: 'chat',
    description: 'Google Gemini 1.5 Flash-8B model for high-volume tasks.',
    isConfigured: true,
    color: '#4285F4',
    endpoint: 'chat',
    rateLimits: {
      tpm: 100000,
      rpm: 60,
    },
  },
  {
    id: 'gemini-1.0-pro',
    name: 'Gemini 1.0 Pro',
    provider: 'gemini',
    category: 'chat',
    description: 'Google Gemini 1.0 Pro model for text and code tasks.',
    isConfigured: true,
    color: '#4285F4',
    endpoint: 'chat',
    rateLimits: {
      tpm: 60000,
      rpm: 45,
    },
  }
];
