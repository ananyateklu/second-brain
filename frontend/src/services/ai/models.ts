import { AIModel } from '../../types/ai';

export const AI_MODELS: AIModel[] = [
  // OpenAI GPT-4 Models
  {
    id: 'gpt-4',
    name: 'GPT-4',
    provider: 'openai',
    category: 'chat',
    description: 'Most capable base GPT-4 model',
    isConfigured: true,
    color: '#6B7280',
    endpoint: 'chat',
    rateLimits: {
      tpm: 10000,
      rpm: 500,
      rpd: 10000,
      tpd: 100000,
    },
  },
  {
    id: 'gpt-4-turbo',
    name: 'GPT-4 Turbo',
    provider: 'openai',
    category: 'chat',
    description: 'Enhanced GPT-4 with higher rate limits',
    isConfigured: true,
    color: '#6B7280',
    endpoint: 'chat',
    rateLimits: {
      tpm: 30000,
      rpm: 500,
      tpd: 90000,
    },
  },
  {
    id: 'gpt-4o',
    name: 'GPT-4 Optimized',
    provider: 'openai',
    category: 'chat',
    description: 'Optimized version of GPT-4',
    isConfigured: true,
    color: '#6B7280',
    endpoint: 'chat',
    rateLimits: {
      tpm: 30000,
      rpm: 500,
      tpd: 90000,
    },
  },
  {
    id: 'gpt-4o-mini',
    name: 'GPT-4 Optimized Mini',
    provider: 'openai',
    category: 'chat',
    description: 'Lightweight GPT-4 with higher token limits',
    isConfigured: true,
    color: '#6B7280',
    endpoint: 'chat',
    rateLimits: {
      tpm: 200000,
      rpm: 500,
      rpd: 10000,
      tpd: 2000000,
    },
  },
  {
    id: 'gpt-3.5-turbo',
    name: 'GPT-3.5 Turbo',
    provider: 'openai',
    category: 'chat',
    description: 'Fast and cost-effective chat model',
    isConfigured: true,
    color: '#6B7280',
    endpoint: 'chat',
    rateLimits: {
      tpm: 200000,
      rpm: 500,
      rpd: 10000,
      tpd: 2000000,
    },
  },
  // OpenAI Embedding Models
  {
    id: 'text-embedding-3-small',
    name: 'Text Embedding 3 Small',
    provider: 'openai',
    category: 'embedding',
    description: 'Efficient text embedding generation',
    isConfigured: true,
    color: '#6B7280',
    endpoint: 'embeddings',
    rateLimits: {
      tpm: 1000000,
      rpm: 3000,
      tpd: 3000000,
    },
  },
  // OpenAI Image Models
  {
    id: 'dall-e-3',
    name: 'DALLÂ·E 3',
    provider: 'openai',
    category: 'image',
    description: 'Advanced image generation',
    isConfigured: true,
    color: '#6B7280',
    endpoint: 'images',
    rateLimits: {
      rpm: 500,
      imagesPerMinute: 5,
    },
  },
  // OpenAI Audio Models
  {
    id: 'whisper-1',
    name: 'Whisper v1',
    provider: 'openai',
    category: 'audio',
    description: 'Speech to text transcription',
    isConfigured: true,
    color: '#6B7280',
    endpoint: 'audio',
    rateLimits: {
      rpm: 500,
    },
  },
  {
    id: 'tts-1',
    name: 'TTS-1',
    provider: 'openai',
    category: 'audio',
    description: 'Text to speech conversion',
    isConfigured: true,
    color: '#6B7280',
    endpoint: 'audio',
    rateLimits: {
      rpm: 500,
    },
  },
  // Anthropic Models (Mocked for now)
  {
    id: 'claude-3-opus-latest',
    name: 'Claude 3 Opus',
    provider: 'anthropic',
    category: 'chat',
    description: 'Most capable Claude model',
    isConfigured: true,
    color: '#f97316',
    endpoint: 'chat',
  },
  {
    id: 'claude-3-5-sonnet-latest',
    name: 'Claude 3 Sonnet (New)',
    provider: 'anthropic',
    category: 'chat',
    description: 'Claude 3.5 Sonnet - Anthropic\'s latest language model',
    isConfigured: true,
    color: '#f97316',
    endpoint: 'chat',
  },
  {
    id: 'claude-3-haiku-20240307',
    name: 'Claude 3 Haiku',
    provider: 'anthropic',
    category: 'chat',
    description: 'Fastest and most compact Claude 3 model',
    isConfigured: true,
    color: '#f97316',
    endpoint: 'chat',
  },
  {
    id: 'llama3.1:8b',
    name: 'Llama 3.1',
    provider: 'llama',
    category: 'chat',
    description: 'Llama 3.1 - Meta\'s latest 8b parameter model',
    isConfigured: true,
    color: '#6B7280',
    endpoint: 'chat',
  },
  {
    id: 'llama3.2',
    name: 'Llama 3.2',
    provider: 'llama',
    category: 'chat',
    description: 'Llama 3.2 - Meta\'s latest 3b parameter model',
    isConfigured: true,
    color: '#6B7280',
    endpoint: 'chat',
  },
  {
    id: 'codegemma',
    name: 'Code Gemma',
    provider: 'llama',
    category: 'chat',
    description: 'Local Code Gemma model (7b parameters) from Google via Ollama',
    isConfigured: true,
    color: '#FFB74D',
    endpoint: 'chat',

  },
  {
    id: 'gemma2:9b',
    name: 'Gemma 2',
    provider: 'llama',
    category: 'chat',
    description: 'Gemma 2 - Google\'s latest 9b parameter model',
    isConfigured: true,
    color: '#6B7280',
    endpoint: 'chat',
  },
  {
    id: 'nemotron-mini',
    name: 'Nemotron Mini',
    provider: 'llama',
    category: 'chat',
    description: 'A commercial-friendly small language model by NVIDIA optimized for roleplay, RAG QA, and function calling.',
    isConfigured: true,
    color: '#6B7280',
    endpoint: 'chat',
  },
  {
    id: 'Mistral-nemo',
    name: 'Mistral Nemo',
    provider: 'llama',
    category: 'chat',
    description: 'A state-of-the-art 12B model with 128k context length, built by Mistral AI in collaboration with NVIDIA.',
    isConfigured: true,
    color: '#6B7280',
    endpoint: 'chat',
  },
  {
    id: 'starcoder2:7b',
    name: 'Star Coder 2 ',
    provider: 'llama',
    category: 'chat',
    description: 'StarCoder2 is the next generation of transparently trained open code LLMs that comes in three sizes: 3B, 7B and 15B parameters.',
    isConfigured: true,
    color: '#6B7280',
    endpoint: 'chat',
  },
  {
    id: 'orca2',
    name: 'Orca 2',
    provider: 'llama',
    category: 'chat',
    description: 'Orca 2 is built by Microsoft research, and are a fine-tuned version of Meta\'s Llama 2 models. The model is designed to excel particularly in reasoning.',
    isConfigured: true,
    color: '#6B7280',
    endpoint: 'chat',
  },
  {
    id: 'samantha-mistral',
    name: 'Samantha Mistral',
    provider: 'llama',
    category: 'chat',
    description: 'A companion assistant trained in philosophy, psychology, and personal relationships. Based on Mistral.',
    isConfigured: true,
    color: '#6B7280',
    endpoint: 'chat',
  },
  {
    id: 'nexusraven',
    name: 'Nexus Raven (Tool Calling)',
    provider: 'llama',
    category: 'chat',
    description: 'Nexus Raven is a model designed to excel in function calling, and is optimized for tool calling.',
    isConfigured: true,
    color: '#6B7280',
    endpoint: 'chat',
  },
  {
    id: 'granite3-dense:8b',
    name: 'Granite 3 Dense',
    provider: 'llama',
    category: 'chat',
    description: 'The IBM Granite 2B and 8B models are designed to support tool-based use cases and support for retrieval augmented generation (RAG), streamlining code generation, translation and bug fixing.',
    isConfigured: true,
    color: '#6B7280',
    endpoint: 'chat',
  },
  {
    id: 'granite3-moe',
    name: 'Granite 3 MOE',
    provider: 'llama',
    category: 'chat',
    description: 'The IBM Granite 1B and 3B models are the first mixture of experts (MoE) Granite models from IBM designed for low latency usage.',
    isConfigured: true,
    color: '#6B7280',
    endpoint: 'chat',
  },
  {
    id: 'qwen2.5-coder',
    name: 'Qwen 2.5 Coder',
    provider: 'llama',
    category: 'chat',
    description: 'The latest series of Code-Specific Qwen models, with significant improvements in code generation, code reasoning, and code fixing.',
    isConfigured: true,
    color: '#6B7280',
    endpoint: 'chat',
  },
  {
    id: 'phi3.5',
    name: 'Phi 3.5',
    provider: 'llama',
    category: 'chat',
    description: 'A lightweight AI model with 3.8 billion parameters with performance overtaking similarly and larger sized models.',
    isConfigured: true,
    color: '#6B7280',
    endpoint: 'chat',
  }
];
