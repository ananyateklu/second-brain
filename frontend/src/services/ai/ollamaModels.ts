import { AIModel } from '../../types/ai';

export const OLLAMA_MODELS: AIModel[] = [
    {
        id: 'llama3.1:8b-agent',
        name: 'Llama 3.1 (Agent)',
        provider: 'ollama',
        category: 'agent',
        description: "Llama 3.1 - Meta's latest 8b parameter model optimized for agent tasks",
        isConfigured: true,
        isReasoner: true,
        color: '#8B5CF6',
        endpoint: 'agent',
        size: '8B',
        rateLimits: {
            tpm: 60000,
            rpm: 35,
            maxInputTokens: 128000,
            maxOutputTokens: 4096,
        },
    },
    {
        id: 'llama3.2-agent',
        name: 'Llama 3.2 (Agent)',
        provider: 'ollama',
        category: 'agent',
        description: "Llama 3.2 - Meta's latest 3b parameter model",
        isConfigured: true,
        isReasoner: true,
        color: '#8B5CF6',
        endpoint: 'agent',
        size: '3B',
        rateLimits: {
            tpm: 80000,
            rpm: 45,
            maxInputTokens: 128000,
            maxOutputTokens: 4096,
        },
    },
    {
        id: 'deepseek-coder-v2-agent',
        name: 'DeepSeek Coder V2 (Agent)',
        provider: 'ollama',
        category: 'agent',
        description: 'An open-source Mixture-of-Experts code language model that achieves performance comparable to GPT4-Turbo in code-specific tasks.',
        isConfigured: true,
        isReasoner: true,
        color: '#8B5CF6',
        endpoint: 'agent',
        rateLimits: {
            tpm: 60000,
            rpm: 35,
            maxInputTokens: 16384,
            maxOutputTokens: 4096,
        },
        size: '33B',
    },
    {
        id: 'nemotron-mini-agent',
        name: 'Nemotron Mini (Agent)',
        provider: 'ollama',
        category: 'agent',
        description: 'A commercial-friendly small language model by NVIDIA optimized for roleplay, RAG QA, and function calling.',
        isConfigured: true,
        isReasoner: true,
        color: '#8B5CF6',
        endpoint: 'agent',
        rateLimits: {
            tpm: 60000,
            rpm: 35,
            maxInputTokens: 16384,
            maxOutputTokens: 4096,
        },
    },
    {
        id: 'nemotron-agent',
        name: 'Nemotron (Agent)',
        provider: 'ollama',
        category: 'agent',
        description: 'A commercial-friendly small language model by NVIDIA optimized for roleplay, RAG QA, and function calling.',
        isConfigured: true,
        isReasoner: true,
        color: '#8B5CF6',
        endpoint: 'agent',
        rateLimits: {
            tpm: 60000,
            rpm: 35,
            maxInputTokens: 16384,
            maxOutputTokens: 4096,
        },
    },
    {
        id: 'Mistral-nemo-agent',
        name: 'Mistral Nemo (Agent)',
        provider: 'ollama',
        category: 'agent',
        description: 'A state-of-the-art 12B model with 128k context length, built by Mistral AI in collaboration with NVIDIA.',
        isConfigured: true,
        isReasoner: true,
        color: '#8B5CF6',
        endpoint: 'agent',
        rateLimits: {
            tpm: 60000,
            rpm: 35,
            maxInputTokens: 16384,
            maxOutputTokens: 4096,
        },
    },
    {
        id: 'orca2-agent',
        name: 'Orca 2 (Agent)',
        provider: 'ollama',
        category: 'agent',
        description: "Orca 2 is built by Microsoft research, and are a fine-tuned version of Meta's Llama 2 models. The model is designed to excel particularly in reasoning.",
        isConfigured: true,
        isReasoner: true,
        color: '#8B5CF6',
        endpoint: 'agent',
        rateLimits: {
            tpm: 60000,
            rpm: 35,
            maxInputTokens: 16384,
            maxOutputTokens: 4096,
        },
    },
    {
        id: 'granite3.1-dense:latest',
        name: 'Granite 3.1 Dense',
        provider: 'ollama',
        category: 'agent',
        description: 'The IBM Granite 2B and 8B models are text-only dense LLMs trained on over 12 trillion tokens of data, demonstrated significant improvements over their predecessors in performance and speed in IBMs initial testing.',
        isConfigured: true,
        isReasoner: false,
        color: '#8B5CF6',
        endpoint: 'agent',
        rateLimits: {
            tpm: 60000,
            rpm: 35,
            maxInputTokens: 16384,
            maxOutputTokens: 4096,
        },
        size: '8B',
    },
    {
        id: 'granite3-dense:8b-agent',
        name: 'Granite 3 Dense (Agent)',
        provider: 'ollama',
        category: 'agent',
        description: 'The IBM Granite 2B and 8B models are designed to support tool-based use cases and support for retrieval augmented generation (RAG), streamlining code generation, translation and bug fixing.',
        isConfigured: true,
        isReasoner: true,
        color: '#8B5CF6',
        endpoint: 'agent',
        rateLimits: {
            tpm: 60000,
            rpm: 35,
            maxInputTokens: 16384,
            maxOutputTokens: 4096,
        },
        size: '8B',
    },
    {
        id: 'granite3-moe-agent',
        name: 'Granite 3 MOE (Agent)',
        provider: 'ollama',
        category: 'agent',
        description: 'The IBM Granite 1B and 3B models are the first mixture of experts (MoE) Granite models from IBM designed for low latency usage.',
        isConfigured: true,
        isReasoner: true,
        color: '#8B5CF6',
        endpoint: 'agent',
        rateLimits: {
            tpm: 80000,
            rpm: 45,
            maxInputTokens: 16384,
            maxOutputTokens: 4096,
        },
    },
    {
        id: 'qwen2.5-coder:3b-agent',
        name: 'Qwen 2.5 Coder 3b (Agent)',
        provider: 'ollama',
        category: 'agent',
        description: 'The latest series of Code-Specific Qwen models, with significant improvements in code generation, code reasoning, and code fixing.',
        isConfigured: true,
        isReasoner: true,
        color: '#8B5CF6',
        endpoint: 'agent',
        size: '3B',
        rateLimits: {
            tpm: 80000,
            rpm: 45,
            maxInputTokens: 16384,
            maxOutputTokens: 4096,
        },
    },
    {
        id: 'qwen2.5-coder:14b-agent',
        name: 'Qwen 2.5 Coder 14b (Agent)',
        provider: 'ollama',
        category: 'agent',
        description: 'The latest series of Code-Specific Qwen models, with significant improvements in code generation, code reasoning, and code fixing.',
        isConfigured: true,
        isReasoner: true,
        color: '#8B5CF6',
        endpoint: 'agent',
        size: '14B',
        rateLimits: {
            tpm: 60000,
            rpm: 35,
            maxInputTokens: 16384,
            maxOutputTokens: 4096,
        },
    },
    {
        id: 'qwen2.5-coder:32b-agent',
        name: 'Qwen 2.5 Coder 32b (Agent)',
        provider: 'ollama',
        category: 'agent',
        description: 'The latest series of Code-Specific Qwen models, with significant improvements in code generation, code reasoning, and code fixing.',
        isConfigured: true,
        isReasoner: true,
        color: '#8B5CF6',
        endpoint: 'agent',
        size: '32B',
        rateLimits: {
            tpm: 40000,
            rpm: 25,
            maxInputTokens: 128000,
            maxOutputTokens: 4096,
        },
    },
    {
        id: 'phi3.5-agent',
        name: 'Phi 3.5 (Agent)',
        provider: 'ollama',
        category: 'agent',
        description: 'A lightweight AI model with 3.8 billion parameters with performance overtaking similarly and larger sized models.',
        isConfigured: true,
        isReasoner: true,
        color: '#8B5CF6',
        endpoint: 'agent',
        size: '3.8B',
        rateLimits: {
            tpm: 80000,
            rpm: 45,
            maxInputTokens: 16384,
            maxOutputTokens: 4096,
        },
    },
    {
        id: 'phi3:14b-agent',
        name: 'Phi 3 14b (Agent)',
        provider: 'ollama',
        category: 'agent',
        description: 'Phi-3 is a family of lightweight 3B (Mini) and 14B (Medium) state-of-the-art open models by Microsoft.',
        isConfigured: true,
        isReasoner: true,
        color: '#8B5CF6',
        endpoint: 'agent',
        size: '14B',
        rateLimits: {
            tpm: 60000,
            rpm: 35,
            maxInputTokens: 16384,
            maxOutputTokens: 4096,
        },
    },
    {
        id: 'codegemma-agent',
        name: 'Code Gemma (Agent)',
        provider: 'ollama',
        category: 'agent',
        description: 'Local Code Gemma model (7b parameters) from Google via Ollama',
        isConfigured: true,
        isReasoner: true,
        color: '#8B5CF6',
        endpoint: 'agent',
        rateLimits: {
            tpm: 60000,
            rpm: 35,
            maxInputTokens: 16384,
            maxOutputTokens: 4096,
        },
        size: '7B',
    },
    {
        id: 'gemma2:9b-agent',
        name: 'Gemma 2 (Agent)',
        provider: 'ollama',
        category: 'agent',
        description: "Gemma 2 - Google's latest 9b parameter model",
        isConfigured: true,
        isReasoner: true,
        color: '#8B5CF6',
        endpoint: 'agent',
        size: '9B',
        rateLimits: {
            tpm: 60000,
            rpm: 35,
            maxInputTokens: 16384,
            maxOutputTokens: 4096,
        },
    },
    {
        id: 'gemma2:2b-agent',
        name: 'Gemma 2 2b (Agent)',
        provider: 'ollama',
        category: 'agent',
        description: 'Local Gemma 2 model (2b parameters) from Google via Ollama',
        isConfigured: true,
        isReasoner: true,
        color: '#8B5CF6',
        endpoint: 'agent',
        size: '2B',
        rateLimits: {
            tpm: 80000,
            rpm: 45,
            maxInputTokens: 16384,
            maxOutputTokens: 4096,
        },
    },
    {
        id: 'opencoder:8b-agent',
        name: 'OpenCoder 8b (Agent)',
        provider: 'ollama',
        category: 'agent',
        description: 'OpenCoder is an open and reproducible code LLM family which includes 1.5B and 8B models, supporting both chat and fill-in-the-middle for English and Chinese languages.',
        isConfigured: true,
        isReasoner: true,
        color: '#8B5CF6',
        endpoint: 'agent',
        size: '8B',
        rateLimits: {
            tpm: 60000,
            rpm: 35,
            maxInputTokens: 16384,
            maxOutputTokens: 4096,
        },
    },
    {
        id: 'opencoder:1.5b-agent',
        name: 'OpenCoder 1.5b (Agent)',
        provider: 'ollama',
        category: 'agent',
        description: 'OpenCoder is an open and reproducible code LLM family which includes 1.5B and 8B models, supporting both chat and fill-in-the-middle for English and Chinese languages.',
        isConfigured: true,
        isReasoner: true,
        color: '#8B5CF6',
        endpoint: 'agent',
        size: '1.5B',
        rateLimits: {
            tpm: 80000,
            rpm: 45,
            maxInputTokens: 16384,
            maxOutputTokens: 4096,
        },
    },
]; 